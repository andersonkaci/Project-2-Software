# -*- coding: utf-8 -*-
"""SoftwareProject2Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sgfG0-vCVZW7RBkoaHqpTDXBDTu_M9qi

[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)

# How to Train YOLO11 Object Detection on a Custom Dataset

---

[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/ultralytics/ultralytics)

YOLO11 builds on the advancements introduced in YOLOv9 and YOLOv10 earlier this year, incorporating improved architectural designs, enhanced feature extraction techniques, and optimized training methods.

YOLO11m achieves a higher mean mAP score on the COCO dataset while using 22% fewer parameters than YOLOv8m, making it computationally lighter without sacrificing performance.

YOLOv11 is available in 5 different sizes, ranging from `2.6M` to `56.9M` parameters, and capable of achieving from `39.5` to `54.7` mAP on the COCO dataset.

# Setup
"""

import os

HOME = os.getcwd()
print(HOME)

# Install necessary libraries
!pip install ultralytics roboflow

import ultralytics
from roboflow import Roboflow

ultralytics.checks()

"""# Train Custom YOLOv11 Model

Import Roboflow Custom Dataset
"""

# Create dataset directory
DATASET_DIR = f"{HOME}/datasets"
os.makedirs(DATASET_DIR, exist_ok=True)

# Download dataset using Roboflow
rf = Roboflow(api_key="0ePQ94rurAqXYZz9Cxib")
project = rf.workspace("project2-hhxsv").project("project2-kawzx")
version = project.version(4)
dataset = version.download("yolov11")

"""Train Custom Model"""

# Train YOLO model
!yolo task=detect mode=train model=yolov11s.pt data={dataset.location}/data.yaml epochs=100 imgsz=640 plots=True

# List training results
!ls {HOME}/runs/detect/train/

# Display training metrics
from IPython.display import Image as IPyImage

IPyImage(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=600)
IPyImage(filename=f'{HOME}/runs/detect/train/results.png', width=600)

"""# Validate fine-tuned Model"""

# Validate YOLO model
!yolo task=detect mode=val model={HOME}/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml

"""# Inference with Custom Model"""

# Predict with YOLO model
!yolo task=detect mode=predict model={HOME}/runs/detect/train/weights/best.pt conf=0.25 source={dataset.location}/test/images save=True

# Display predictions
import glob
from IPython.display import Image as IPyImage, display

prediction_images = sorted(glob.glob(f"{HOME}/runs/detect/predict/*.jpg"), key=os.path.getmtime, reverse=True)

for img_path in prediction_images[:10]:
    display(IPyImage(filename=img_path, width=600))

"""# Video"""

# Install additional libraries
!pip install opencv-python-headless ffmpeg-python

# Video processing
import cv2
from ultralytics import YOLO
from IPython.display import Video

model_path = f"{HOME}/runs/detect/train/weights/best.pt"
input_video_path = f"{HOME}/TestPictures/Videos/MultipleDogWalking.mp4"
output_video_path = f"{HOME}/output_video.mp4"

cap = cv2.VideoCapture(input_video_path)
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = int(cap.get(cv2.CAP_PROP_FPS))

fourcc = cv2.VideoWriter_fourcc(*"mp4v")
out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))

model = YOLO(model_path)

try:
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        results = model(frame)

        for detection in results[0].boxes:
            x1, y1, x2, y2 = map(int, detection.xyxy[0])
            conf = detection.conf[0]
            cls = int(detection.cls[0])
            label = f"{model.names[cls]} {conf:.2f}"

            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        out.write(frame)
finally:
    cap.release()
    out.release()

print(f"Processed video saved to: {output_video_path}")

# Display processed video
Video(output_video_path, embed=True)
